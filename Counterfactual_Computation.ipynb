{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Counterfactual Computation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CHzqEQW8qZUM",
        "Q7AzwDhvuHX-",
        "nyGDsY2j4NfG"
      ],
      "authorship_tag": "ABX9TyN44LuO6wGS/u1X0Q6q4d3m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahantesh-Pattadkal-1993/CounterFactuals_GANs/blob/main/Counterfactual_Computation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWIBBfXcP_kz",
        "outputId": "6ea324f8-f68b-4c3f-efc7-561cacd751ba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uma5W4TFQSwX"
      },
      "source": [
        "#Setting up the path for GAN Training\n",
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/Github/CounterFactuals_GANs/MNIST')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amOxIb6xQVbM",
        "outputId": "a25b4075-c531-4b26-9a0e-1085c99492c9"
      },
      "source": [
        "#Import the libraries \n",
        "import torch\n",
        "import torch.optim as opt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from GAN_Models import DC_Generator, DC_Discriminator, Net, CNN, Net_logits\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "manualSeed = 2021\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed:  2021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f372d105110>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vJ-ZtzXmGrs"
      },
      "source": [
        "## Loading the Models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBnkacTUZQu_",
        "outputId": "154a9a89-e8f6-4e0e-d675-c6b25c2b0126"
      },
      "source": [
        "#Load the Generator  \n",
        "# using the 150 epochs dataset\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
        "\n",
        "G = DC_Generator().to(device)\n",
        "D = DC_Discriminator().to(device)\n",
        "\n",
        "\n",
        "checkpoint = torch.load(\"Weights/G_checkpoint_latest_149.pth\", map_location=torch.device('cuda'))\n",
        "G.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "checkpoint = torch.load(\"Weights/D_checkpoint_latest_149.pth\", map_location=torch.device('cuda'))\n",
        "D.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxUuFeUMQdht",
        "outputId": "f09ae4ac-6937-4de4-8b31-69b88479c9ed"
      },
      "source": [
        "#Load the Classifier\n",
        "Classifier_model = Net()\n",
        "Classifier_checkpoint = torch.load(\"Weights/Classifier_CNN.pth\", map_location=torch.device('cuda'))\n",
        "Classifier_model.load_state_dict(Classifier_checkpoint['state_dict'])\n",
        "Classifier_model.eval()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (dropout1): Dropout(p=0.25, inplace=False)\n",
              "  (dropout2): Dropout(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QgUV9HIGHoI",
        "outputId": "a3eb0928-7591-4564-a7cf-d0cedacae696"
      },
      "source": [
        "#Load the Classifier Net_logits() and outputs :- softmax, logits\n",
        "Classifier_model_logits = Net_logits().to(device)\n",
        "Classifier_checkpoint = torch.load(\"Weights/Classifier_CNN_logits.pth\", map_location=torch.device('cuda'))\n",
        "Classifier_model_logits.load_state_dict(Classifier_checkpoint['state_dict'])\n",
        "Classifier_model_logits.eval()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net_logits(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (dropout1): Dropout(p=0.25, inplace=False)\n",
              "  (dropout2): Dropout(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sur5CGLPYCj4",
        "outputId": "b1ae0602-e3e3-4b5b-dbef-3521ab7545bb"
      },
      "source": [
        "#Load Eoins Classifier\n",
        "Classifier_model_eoin = CNN()\n",
        "Classifier_checkpoint = torch.load(\"Weights/pytorch_cnn.pth\", map_location=torch.device('cpu'))\n",
        "#Classifier_model.load_state_dict(Classifier_checkpoint['state_dict'])\n",
        "Classifier_model_eoin.eval()\n",
        "\n",
        "# Gettin weird predictions, maybe the state dict is missing"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (main): Sequential(\n",
              "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout2d(p=0.1, inplace=False)\n",
              "    (4): Conv2d(8, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Dropout2d(p=0.1, inplace=False)\n",
              "    (8): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU(inplace=True)\n",
              "    (11): Dropout2d(p=0.1, inplace=False)\n",
              "    (12): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "    (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (14): ReLU(inplace=True)\n",
              "    (15): Dropout2d(p=0.2, inplace=False)\n",
              "    (16): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (18): ReLU(inplace=True)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-n1ssDMmLo_"
      },
      "source": [
        "## Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHnhp6XXRCby",
        "outputId": "ba906069-6c21-4963-e212-e3161530ae9f"
      },
      "source": [
        "#Loading the data\n",
        "\n",
        "mb_size = 4\n",
        "\n",
        "transform = transforms.Compose(\n",
        "\t\t[transforms.ToTensor(),\n",
        "\t\t transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "trainData = torchvision.datasets.MNIST('./data/', download=True, transform=transform, train=True)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(trainData, shuffle=False, batch_size=mb_size)\n",
        "\n",
        "dataIter = iter(trainLoader)\n",
        "\n",
        "imgs, labels = dataIter.next()\n",
        "imgs = imgs.to(device)\n",
        "\n",
        "print(imgs.shape)\n",
        "print(labels)\n",
        "imgs.is_cuda"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 1, 28, 28])\n",
            "tensor([5, 0, 4, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "J4QajikfSHfx",
        "outputId": "b907497b-e0d9-446d-ee0a-4bd4b9bda5eb"
      },
      "source": [
        "sample_image = imgs[1,:,:,:] #first image in this batch \n",
        "sample_image= sample_image.reshape([1,1,28,28]) #adding the dimension for batch size\n",
        "sample_image = sample_image.to('cpu') #pushing it to cpu as that numpy conversion can be done\n",
        "\n",
        "\n",
        "npimgs = sample_image[0].detach().numpy()\n",
        "plt.imshow(npimgs[0],cmap='Greys_r')\n",
        "\n",
        "sample_image = sample_image.to('cuda')\n",
        "output, logits = Classifier_model_logits(sample_image)\n",
        "print(output)"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.0000e+00, 8.4316e-11, 1.7799e-08, 5.8022e-12, 1.0353e-11, 1.9533e-13,\n",
            "         2.2826e-09, 1.6658e-10, 1.5405e-11, 1.8834e-11]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--otHGKdTbBh"
      },
      "source": [
        "import torch\n",
        "torch.manual_seed(100)\n",
        "z = torch.randn(1, 100,1,1).to(device)\n",
        "step_size = 0.001"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBQFg3WiaO4G"
      },
      "source": [
        "#find the z_org that respresents the latent representation of given image\n",
        "\n",
        "def latent_representation(z,sample_image,pred):\n",
        "  overall_loss = 0\n",
        "  loss = 0\n",
        "  avg_loss = 1000\n",
        "  avg_loss_old = 1000\n",
        "  i=1\n",
        "  while (avg_loss_old>=avg_loss):\n",
        "    z.requires_grad = True\n",
        "    loss1 = torch.square(torch.abs(sample_image-G(z))).sum() \n",
        "    loss2 = torch.square(torch.abs(Classifier_model_logits(G(z))[0] - Classifier_model_logits(sample_image)[0]).sum())\n",
        "    #loss2 = torch.square(torch.abs(Classifier_model_logits(G(z)) - Classifier_model_logits(sample_image)).sum()) # use when Net() model is used\n",
        "    \n",
        "\n",
        "    loss = loss1 + loss2\n",
        "\n",
        "    z.grad = None\n",
        "    loss.backward()\n",
        "    z.requires_grad = False\n",
        "    z = z - z.grad * step_size\n",
        "    i = i+1\n",
        "\n",
        "    overall_loss= overall_loss + loss\n",
        "    if (i%500==0):\n",
        "      #print(\"loss \" + \"step \" + str(i) + str (loss))\n",
        "      avg_loss_old = avg_loss\n",
        "      avg_loss = overall_loss/500.0\n",
        "      print(\"avg_loss \" + \"step \" + \" \" +str(i) + str (avg_loss))\n",
        "      \n",
        "      overall_loss = 0 \n",
        "    \n",
        "    if(i==10000):\n",
        "      break\n",
        "\n",
        "  return z\n",
        "\n",
        "z_org = latent_representation(z,sample_image,4)\n",
        "\n",
        "G_img= G(z_org) #generate the img\n",
        "G_img = G_img.to('cpu')  # bring it to cpu\n",
        "npimgs = G_img[0].detach().numpy()  #plot the image\n",
        "print(npimgs.shape)\n",
        "plt.imshow(npimgs[0],cmap='Greys_r')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJCFW5KPwnBn",
        "outputId": "dffc8707-6684-448f-a014-2f9dca46fe15"
      },
      "source": [
        "Classifier_model_logits(G(z))[0]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3555e-06, 9.3431e-12, 2.9211e-12, 1.9332e-12, 3.1462e-12, 5.2353e-05,\n",
              "         9.9993e-01, 1.9209e-13, 2.0184e-05, 2.9865e-13]], device='cuda:0',\n",
              "       grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "oYx7s9Ljso8V",
        "outputId": "8726ae42-4a1d-488b-b212-db55063c0de9"
      },
      "source": [
        "# Using the standard loss functions\n",
        "#find the z_org that respresents the latent representation of given image\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "torch.manual_seed(100)\n",
        "z= torch.randn(1, 100,1,1).to(device)\n",
        "step_size = 0.1\n",
        "\n",
        "#Find the image closer to the original one but target prediction\n",
        "MSE = nn.MSELoss()\n",
        "nll = nn.NLLLoss()\n",
        "CE_loss = nn.CrossEntropyLoss()\n",
        "l1_loss = nn.L1Loss()\n",
        "optimizer = optim.SGD([z_semi], lr=0.01) #not using optimiser here\n",
        "\n",
        "\n",
        "def latent_representation(z,sample_image):\n",
        "  overall_loss, loss , avg_loss = 0,10,0\n",
        "  i=1\n",
        "\n",
        "  while (loss>=0.09):\n",
        "    z.requires_grad = True\n",
        "    loss1 = MSE(sample_image,G(z)) #pixel loss\n",
        "    loss2 = MSE(Classifier_model_logits(G(z))[0] , Classifier_model_logits(sample_image)[0]) #diference in pred of both images\n",
        "    \n",
        "    loss = loss1 + loss2\n",
        "    #print(loss)\n",
        "\n",
        "    z.grad = None\n",
        "    loss.backward()\n",
        "    z.requires_grad = False\n",
        "    z = z - z.grad * step_size\n",
        "    i = i+1\n",
        "\n",
        "    overall_loss= overall_loss + loss\n",
        "    if (i%500==0):\n",
        "            \n",
        "      avg_loss = overall_loss/500.0\n",
        "      print(\"avg_loss \" + \"step \" + \" \" +str(i) + str (avg_loss))\n",
        "      overall_loss = 0 \n",
        "    \n",
        "\n",
        "  return z\n",
        "\n",
        "z_org = latent_representation(z,sample_image)\n",
        "\n",
        "G_img= G(z_org) #generate the img\n",
        "G_img = G_img.to('cpu')  # bring it to cpu\n",
        "npimgs = G_img[0].detach().numpy()  #plot the image\n",
        "print(npimgs.shape)\n",
        "plt.imshow(npimgs[0],cmap='Greys_r')\n",
        "\n",
        "\n"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg_loss step  500tensor(0.5528, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  1000tensor(0.4814, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  1500tensor(0.4655, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  2000tensor(0.4573, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  2500tensor(0.4534, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  3000tensor(0.3609, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  3500tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  4000tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  4500tensor(0.2281, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  5000tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  5500tensor(0.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  6000tensor(0.2013, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  6500tensor(0.1961, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  7000tensor(0.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  7500tensor(0.1871, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  8000tensor(0.1823, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  8500tensor(0.1783, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  9000tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  9500tensor(0.1685, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  10000tensor(0.1581, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  10500tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  11000tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  11500tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  12000tensor(0.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  12500tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  13000tensor(0.1318, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  13500tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  14000tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  14500tensor(0.1241, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  15000tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  15500tensor(0.1209, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  16000tensor(0.1200, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "avg_loss step  16500tensor(0.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "(1, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f370fd95a90>"
            ]
          },
          "metadata": {},
          "execution_count": 188
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "jwFnkbGWy11p",
        "outputId": "265e0534-97cd-4af6-9a8d-47cb8695e385"
      },
      "source": [
        "G_img= G(z) #generate the img\n",
        "G_img = G_img.to('cpu')  # bring it to cpu\n",
        "npimgs = G_img[0].detach().numpy()  #plot the image\n",
        "print(npimgs.shape)\n",
        "plt.imshow(npimgs[0],cmap='Greys_r')\n"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f370feb0d90>"
            ]
          },
          "metadata": {},
          "execution_count": 186
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHzqEQW8qZUM"
      },
      "source": [
        "## Latent dimension loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "2FRhTyamqTNh",
        "outputId": "ff6e7abb-3a35-4e47-c94c-93dc95f033f1"
      },
      "source": [
        "#using latent dimension euclidean distance and PR loss\n",
        "import torch\n",
        "torch.manual_seed(100)\n",
        "z = torch.randn(1, 100,1,1).to(device)\n",
        "step_size = 0.001\n",
        "\n",
        "\n",
        "def counterfactual_eluclidian(z,z_org,target_class):\n",
        "\n",
        "  overall_loss = 0\n",
        "  loss = 0\n",
        "  avg_loss = 1000\n",
        "  avg_loss_old = 1000\n",
        "  i=1\n",
        "  while (avg_loss_old>=avg_loss):\n",
        "    z.requires_grad = True\n",
        "    loss1 = torch.square(torch.abs(z_org-z)).sum() #latent dim euclidean loss\n",
        "    loss2 = torch.log(Classifier_model_logits(G(z))[0][0][target_class]) #as classifier gives 2 outputs we take 0th index\n",
        "    loss3 = torch.log(D(G(z))) #plausibility\n",
        "\n",
        "    loss = loss1 - loss2 \n",
        "    #loss = loss1 - 10*loss2\n",
        "\n",
        "    z.grad = None\n",
        "    loss.backward()\n",
        "    z.requires_grad = False\n",
        "    z = z - z.grad * step_size\n",
        "    i = i+1\n",
        "\n",
        "    overall_loss= overall_loss + loss\n",
        "    if (i%500==0):\n",
        "      #print(\"loss \" + \"step \" + str(i) + str (loss))\n",
        "      avg_loss_old = avg_loss\n",
        "      avg_loss = overall_loss/500.0\n",
        "      print(\"avg_loss \" + \"step \" + \" \" +str(i) + str (avg_loss))\n",
        "      print(\"avg_loss_old \" + \"step \" + str(i) + str (avg_loss_old))\n",
        "      overall_loss = 0 \n",
        "  return z, loss1, loss2, loss3\n",
        "\n",
        "target_class = 1\n",
        "z_eucli, loss1, loss2, loss3 = counterfactual_eluclidian(z,z_org,target_class)\n",
        "#Check if the image generated is close to the real image\n",
        "\n",
        "G_img= G(z_eucli)\n",
        "npimgs = G_img[0].detach().numpy()\n",
        "print(npimgs.shape)\n",
        "plt.imshow(npimgs[0],cmap='Greys_r')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg_loss step  500tensor(44.3367, grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 5001000\n",
            "avg_loss step  1000tensor(11.3798, grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 1000tensor(44.3367, grad_fn=<DivBackward0>)\n",
            "avg_loss step  1500tensor(5.1295, grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 1500tensor(11.3798, grad_fn=<DivBackward0>)\n",
            "avg_loss step  2000tensor(4.1300, grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 2000tensor(5.1295, grad_fn=<DivBackward0>)\n",
            "avg_loss step  2500tensor(3.9595, grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 2500tensor(4.1300, grad_fn=<DivBackward0>)\n",
            "avg_loss step  3000tensor(3.9356, grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 3000tensor(3.9595, grad_fn=<DivBackward0>)\n",
            "avg_loss step  3500tensor(3.9402, grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 3500tensor(3.9356, grad_fn=<DivBackward0>)\n",
            "(1, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbb386abb50>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFnCruWDtsLu",
        "outputId": "2e2feda7-da48-45e2-d0f4-e3d8aa5b7b91"
      },
      "source": [
        "Classifier_model_logits(G(z_eucli))[0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.8972e-03, 4.9882e-01, 1.5683e-01, 6.7859e-02, 1.2414e-01, 2.1038e-05,\n",
              "         1.3386e-01, 1.0421e-02, 6.0656e-03, 8.5337e-05]],\n",
              "       grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "0ejFwG9tsNvD",
        "outputId": "b13dbdcd-74fd-449c-fe0a-6e320ba7309b"
      },
      "source": [
        "#using latent dimension distance and without PR loss\n",
        "\n",
        "#This can be used as the baselines that do not talk about plausibility\n",
        "\n",
        "import torch\n",
        "torch.manual_seed(100)\n",
        "z = torch.randn(1, 100,1,1).to(device)\n",
        "step_size = 0.001\n",
        "\n",
        "\n",
        "def counterfactual_eluclidian(z,z_org,target_class):\n",
        "\n",
        "  overall_loss = 0\n",
        "  loss = 0\n",
        "  avg_loss = 1000\n",
        "  avg_loss_old = 1000\n",
        "  i=1\n",
        "  while (avg_loss_old>=avg_loss):\n",
        "    z.requires_grad = True\n",
        "    loss1 = torch.square(torch.abs(z_org-z)).sum() \n",
        "    loss2 = torch.log(Classifier_model_logits(G(z))[0][0][target_class])\n",
        "    loss3 = torch.log(D(G(z)))\n",
        "\n",
        "    #loss = loss1 - 10*loss2 - loss3\n",
        "    loss = loss1 - 10*loss2\n",
        "\n",
        "    z.grad = None\n",
        "    loss.backward()\n",
        "    z.requires_grad = False\n",
        "    z = z - z.grad * step_size\n",
        "    i = i+1\n",
        "\n",
        "    overall_loss= overall_loss + loss\n",
        "    if (i%500==0):\n",
        "      #print(\"loss \" + \"step \" + str(i) + str (loss))\n",
        "      avg_loss_old = avg_loss\n",
        "      avg_loss = overall_loss/500.0\n",
        "      print(\"avg_loss \" + \"step \" + \" \" +str(i) + str (avg_loss))\n",
        "      print(\"avg_loss_old \" + \"step \" + str(i) + str (avg_loss_old))\n",
        "      overall_loss = 0 \n",
        "  return z\n",
        "\n",
        "z = counterfactual_eluclidian(z,z_org,3)\n",
        "\n",
        "#Check if the image generated is close to the real image\n",
        "G_img= G(z)\n",
        "npimgs = G_img[0].detach().numpy()\n",
        "print(npimgs.shape)\n",
        "plt.imshow(npimgs[0],cmap='Greys_r')"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg_loss step  500tensor(48.3900, grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 5001000\n",
            "avg_loss step  1000tensor(16.9182, grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 1000tensor(48.3900, grad_fn=<DivBackward0>)\n",
            "avg_loss step  1500tensor(13.0249, grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 1500tensor(16.9182, grad_fn=<DivBackward0>)\n",
            "avg_loss step  2000tensor(12.7657, grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 2000tensor(13.0249, grad_fn=<DivBackward0>)\n",
            "avg_loss step  2500tensor(12.6995, grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 2500tensor(12.7657, grad_fn=<DivBackward0>)\n",
            "avg_loss step  3000tensor(12.6908, grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 3000tensor(12.6995, grad_fn=<DivBackward0>)\n",
            "avg_loss step  3500tensor(12.6878, grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 3500tensor(12.6908, grad_fn=<DivBackward0>)\n",
            "avg_loss step  4000tensor(12.6876, grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 4000tensor(12.6878, grad_fn=<DivBackward0>)\n",
            "avg_loss step  4500tensor(12.6864, grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 4500tensor(12.6876, grad_fn=<DivBackward0>)\n",
            "avg_loss step  5000tensor(12.6871, grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 5000tensor(12.6864, grad_fn=<DivBackward0>)\n",
            "(1, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f03fab9b310>"
            ]
          },
          "metadata": {},
          "execution_count": 177
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCKydwVltbGi"
      },
      "source": [
        "#using latent dimension distance but cosine similarity\n",
        "import torch\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "def counterfactual_cosine(z,z_org,target_class):\n",
        "  #print(target_class)\n",
        "  overall_loss = 0\n",
        "  loss = 0\n",
        "  avg_loss = 1000\n",
        "  avg_loss_old = 1000\n",
        "  i=1\n",
        "  while (avg_loss_old>=avg_loss):\n",
        "    z.requires_grad = True\n",
        "    loss1 =  torch.log(0.1+torch.abs(cos(z_org,z)).mean())\n",
        "    loss2 = torch.log(Classifier_model(G(z))[0][0][target_class])\n",
        "    #print(Classifier_model(G(z))[0][target_class])\n",
        "    loss3 = torch.log(D(G(z)))\n",
        "\n",
        "    loss = -loss1 - loss2 - loss3\n",
        "    #loss = loss1 - 10*loss2\n",
        "\n",
        "    z.grad = None\n",
        "    loss.backward()\n",
        "    z.requires_grad = False\n",
        "    z = z - z.grad * step_size\n",
        "    i = i+1\n",
        "\n",
        "    overall_loss= overall_loss + loss\n",
        "    if (i%500==0):\n",
        "      #print(\"loss \" + \"step \" + str(i) + str (loss))\n",
        "      avg_loss_old = avg_loss\n",
        "      avg_loss = overall_loss/500.0\n",
        "      print(\"loss2\" + \" \" + str(loss2))\n",
        "      print(\"avg_loss \" + \"step \" + \" \" +str(i) + str (avg_loss))\n",
        "      print(\"avg_loss_old \" + \"step \" + str(i) + str (avg_loss_old))\n",
        "      overall_loss = 0 \n",
        "    if(i==10000):\n",
        "      break\n",
        "  \n",
        "  return z, loss1, loss2, loss3\n",
        "\n",
        "\n",
        "torch.manual_seed(100)\n",
        "z= torch.randn(1, 100,1,1).to(device)\n",
        "step_size = 0.01\n",
        "\n",
        "target_class = 1\n",
        "z_cf,loss1, loss2, loss3 = counterfactual_cosine(z,z_org,target_class)\n",
        "#Check if the image generated is close to the real image\n",
        "\n",
        "G_img= G(z_cf)\n",
        "npimgs = G_img[0].detach().numpy()\n",
        "print(npimgs.shape)\n",
        "plt.imshow(npimgs[0],cmap='Greys_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALKaTtg0Jagc"
      },
      "source": [
        "# Save the latent cfs for all the digits from 0-9\n",
        "latent_cfs = []\n",
        "for cnt in range(0,10,1):\n",
        "  torch.manual_seed(100)\n",
        "  z= torch.randn(1, 100,1,1).to(device)\n",
        "  step_size = 0.01\n",
        "\n",
        "  target_class = cnt\n",
        "  z_cf,loss1, loss2, loss3 = counterfactual_cosine(z,z_org,target_class)\n",
        "  latent_cfs.append(z_cf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXNQzeiwFHNk"
      },
      "source": [
        "G_img= G(latent_cfs[0])\n",
        "npimgs = G_img[0].detach().numpy()\n",
        "print(npimgs.shape)\n",
        "plt.imshow(npimgs[0],cmap='Greys_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "7Y5tMQbn2eTP",
        "outputId": "d29c6afe-c0cf-4fd3-ce07-0dda7f0232e8"
      },
      "source": [
        "# Check how the original one looks\n",
        "G_img= G(z_org)\n",
        "npimgs = G_img[0].detach().numpy()\n",
        "print(npimgs.shape)\n",
        "plt.imshow(npimgs[0],cmap='Greys_r')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa886641050>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7AzwDhvuHX-"
      },
      "source": [
        "###Find the image which is on a borderline i.e. semi-factual"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIyWCd2ZuL0f"
      },
      "source": [
        "Idea: Use the metric **Pred - argmax2nd highest** to identify the borderline semi factual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "j65ZpSd4uGZg",
        "outputId": "144ef507-28aa-475e-9a80-81704a936457"
      },
      "source": [
        "#Find the image distant from the original one but still has the same class perdiction\n",
        "\n",
        "#using latent dimension distance\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "import torch\n",
        "torch.manual_seed(100)\n",
        "z_semi = torch.randn(1, 100,1,1).to(device)\n",
        "step_size = 0.01\n",
        "\n",
        "\n",
        "def semifactuals(z_org,z_semi,given_class):\n",
        "  overall_loss = 0\n",
        "  loss = 0\n",
        "  avg_loss = 1000\n",
        "  avg_loss_old = 1000\n",
        "  i=1\n",
        "  while (avg_loss_old>=avg_loss):\n",
        "    z_semi.requires_grad = True\n",
        "    #loss1 = torch.square(torch.abs(z_org-z_semi)).sum() # distance in latent dimension euclidean\n",
        "    \n",
        "    loss1 =  torch.log(0.1+torch.abs(cos(z_org,z_semi)).mean()) # distance using cosine similarity\n",
        "    loss2 = torch.log(Classifier_model(G(z_semi))[0][given_class]) # ensure the class is maintained \n",
        "    temp = Classifier_model(G(z_semi))[0]\n",
        "    loss3 = torch.log(1.000001 - (temp[torch.topk(temp,2).indices[0]] - temp[torch.topk(temp,2).indices[1]])) # diference between highest and argmax 2\n",
        "    loss4 = torch.log(D(G(z_semi))) # Plausibility\n",
        "\n",
        "    \n",
        "    \n",
        "  #loss = loss1 - loss2 - 5*loss3 # without PR\n",
        "    loss = -loss1 - loss2 - loss3 - loss4 #with PR\n",
        "    z_semi.grad = None\n",
        "    loss.backward()\n",
        "    z_semi.requires_grad = False\n",
        "    z_semi = z_semi - z_semi.grad * step_size\n",
        "    i = i+1\n",
        "\n",
        "    overall_loss= overall_loss + loss\n",
        "    if (i%500==0):\n",
        "      #print(\"loss \" + \"step \" + str(i) + str (loss))\n",
        "      avg_loss_old = avg_loss\n",
        "      avg_loss = overall_loss/500.0\n",
        "      print(\"avg_loss \" + \"step \" + \" \" +str(i) + str (avg_loss))\n",
        "      print(\"avg_loss_old \" + \"step \" + str(i) + str (avg_loss_old))\n",
        "      overall_loss = 0 \n",
        "  \n",
        "    if (i==1000):\n",
        "      break\n",
        "\n",
        "  return z_semi\n",
        "\n",
        "#-------------------------------------------------------------------\n",
        "# Run the function from here\n",
        "given_class = 0\n",
        "\n",
        "\n",
        "z_semi = semifactuals(z_semi,z_org,given_class)\n",
        "\n",
        "G_img= G(z_semi)\n",
        "npimgs = G_img[0].detach().numpy()\n",
        "print(npimgs.shape)\n",
        "plt.imshow(npimgs[0],cmap='Greys_r')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg_loss step  500tensor([14.4118], grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 5001000\n",
            "avg_loss step  1000tensor([14.1344], grad_fn=<DivBackward0>)\n",
            "avg_loss_old step 1000tensor([14.4118], grad_fn=<DivBackward0>)\n",
            "(1, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa881853190>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YJZyOUDu5At",
        "outputId": "057465dc-fe23-4851-88c9-7cc5ee20284f"
      },
      "source": [
        "Classifier_model(G(z_semi))[0]"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000e+00, 6.8261e-16, 2.3747e-12, 1.5510e-16, 7.7738e-18, 1.2519e-17,\n",
              "        2.1426e-13, 8.3341e-14, 2.0627e-17, 7.0864e-16],\n",
              "       grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Grw0cPaQvSy6",
        "outputId": "ce653775-fb14-4a99-dea6-ecafc185eb64"
      },
      "source": [
        "torch.topk(Classifier_model(G(z_semi))[0],2)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.topk(values=tensor([1.0000e+00, 2.3747e-12], grad_fn=<TopkBackward>), indices=tensor([0, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVyvVi0qvarn",
        "outputId": "9ce753d3-cac1-47c9-8800-873f264126e9"
      },
      "source": [
        "torch.topk(Classifier_model(G(z_org))[0],2)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.topk(values=tensor([1.0000e+00, 6.3456e-13], grad_fn=<TopkBackward>), indices=tensor([0, 6]))"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Te8MATiweMU",
        "outputId": "bfa51e4b-4e70-4b4c-e0e4-45595a57c3cf"
      },
      "source": [
        "temp =   Classifier_model(G(z_semi))[0]\n",
        "torch.log(1.000001 - (temp[torch.topk(temp,2).indices[0]] - temp[torch.topk(temp,2).indices[1]]))\n",
        "1.1 - (temp[torch.topk(temp,2).indices[0]] - temp[torch.topk(temp,2).indices[1]])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1000, grad_fn=<RsubBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyGDsY2j4NfG"
      },
      "source": [
        "###Find the image which is on a borderline i.e. semi-factual provided a target class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "KW5JYRmG4ONB",
        "outputId": "47169580-3226-4b9d-ecd3-30d45b0ae511"
      },
      "source": [
        "#Find the image distant from the original one but still has the same class perdiction\n",
        "import torch\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "#using latent dimension distance\n",
        "\n",
        "import torch\n",
        "torch.manual_seed(100)\n",
        "z_semi = torch.randn(1, 100,1,1).to(device)\n",
        "step_size = 0.001\n",
        "\n",
        "given_class = 0\n",
        "\n",
        "overall_loss = 0\n",
        "loss = 0\n",
        "avg_loss = 1000\n",
        "avg_loss_old = 1000\n",
        "i=1\n",
        "while (avg_loss_old>=avg_loss):\n",
        "  z_semi.requires_grad = True\n",
        "  #loss1 = torch.square(torch.abs(z_org-z_semi)).sum() # distance in latent dimension\n",
        "  \n",
        "  loss1 = torch.log(0.1+torch.abs(cos(z_org,z_semi)).mean()) # distance using cosine similarity\n",
        "  loss2 = torch.log(Classifier_model(G(z_semi))[0][0][given_class]) # ensure the class is maintained \n",
        "  #temp = Classifier_model(G(z_semi))[0]\n",
        "  #loss3 = torch.log(1.1 - (temp[torch.topk(temp,2).indices[0]] - temp[torch.topk(temp,2).indices[1]])) # diference between highest and argmax 2\n",
        "  loss3 = torch.log(1.0001 - torch.abs((Classifier_model(G(z_semi))[0][0] - Classifier_model(G(z_semi))[0][1]))) # difference between target class and img class\n",
        "  loss4 = torch.log(D(G(z_semi))) # Plausibility\n",
        "\n",
        "  \n",
        "  \n",
        "  loss = -loss1 - loss2 - loss3 -loss4 # without PR\n",
        "  #loss = loss1 - loss2 - 5*loss3 - loss4 #with PR\n",
        "  z_semi.grad = None\n",
        "  loss.backward()\n",
        "  z_semi.requires_grad = False\n",
        "  z_semi = z_semi - z_semi.grad * step_size\n",
        "  i = i+1\n",
        "\n",
        "  overall_loss= overall_loss + loss\n",
        "  if (i%500==0):\n",
        "    #print(\"loss \" + \"step \" + str(i) + str (loss))\n",
        "    avg_loss_old = avg_loss\n",
        "    avg_loss = overall_loss/500.0\n",
        "    print(\"avg_loss \" + \"step \" + \" \" +str(i) + str (avg_loss))\n",
        "    print(\"avg_loss_old \" + \"step \" + str(i) + str (avg_loss_old))\n",
        "    overall_loss = 0 \n",
        " "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-5170ff78c746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mloss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_org\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_semi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# distance using cosine similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mloss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassifier_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_semi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgiven_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ensure the class is maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0;31m#temp = Classifier_model(G(z_semi))[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;31m#loss3 = torch.log(1.1 - (temp[torch.topk(temp,2).indices[0]] - temp[torch.topk(temp,2).indices[1]])) # diference between highest and argmax 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Classifier_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "-KVqNzvO4Vj2",
        "outputId": "33c8f8cf-64dd-4091-c27b-abe0aa4455f6"
      },
      "source": [
        "# Plotting the semi factual image according to the cf found by the latent dimension loss and target class provided\n",
        "G_img= G(z_semi)\n",
        "npimgs = G_img[0].detach().numpy()\n",
        "#print(npimgs.shape)\n",
        "plt.imshow(npimgs[0],cmap='Greys_r')"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa880dc15d0>"
            ]
          },
          "metadata": {},
          "execution_count": 232
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNEy930ofePD"
      },
      "source": [
        "## Using the standard losses for CF calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwi1rqET7vhE"
      },
      "source": [
        "#Using nn.losses\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "torch.manual_seed(100)\n",
        "#z_semi = torch.randn(1, 100,1,1).to(device)\n",
        "step_size = 0.1\n",
        "\n",
        "#Find the image closer to the original one but target prediction\n",
        "criterion1 = nn.MSELoss()\n",
        "nll = nn.NLLLoss()\n",
        "CE_loss = nn.CrossEntropyLoss()\n",
        "l1_loss = nn.L1Loss()\n",
        "BCE = nn.BCELoss()\n",
        "#optimizer = optim.SGD([z_semi], lr=0.01)\n",
        "\n",
        "\n",
        "#using latent dimension distance\n",
        "latent_z = []\n",
        "for cnt in range(2,3,1):\n",
        "  z_semi = z_org.to(device)\n",
        "\n",
        "  overall_loss = 0\n",
        "  i=1\n",
        "  while (i<=2500):\n",
        "    z_semi.requires_grad = True\n",
        "        \n",
        "    loss1 = criterion1(z_org,z_semi) # distance using MSE\n",
        "    loss2 = CE_loss(Classifier_model_logits(G(z_semi))[1],torch.tensor([cnt]).to(device) ) # ensure the class is maintained \n",
        "    loss3 = BCE(D(G(z_semi)), torch.tensor([1.0]).to(device))\n",
        "\n",
        "       \n",
        "    #loss =  loss1 + loss2  # without PR\n",
        "    loss = loss1 + loss2 + 0.01*loss3 #with PR\n",
        "    \n",
        "    z_semi.grad = None\n",
        "    loss.backward(retain_graph=True)  \n",
        "    #optimizer.step()  \n",
        "    z_semi.requires_grad = False\n",
        "    z_semi = z_semi - z_semi.grad * step_size\n",
        "    i = i+1\n",
        "    overall_loss= overall_loss + loss \n",
        "\n",
        "    if (i%500==0):\n",
        "           \n",
        "      avg_loss = overall_loss/500.0\n",
        "      print(\"avg_loss \" + \"step \" + \" \" +str(i) + str (avg_loss))\n",
        "     \n",
        "      overall_loss = 0 \n",
        "  latent_z.append(z_semi)\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "kfSI7W_C_MT_",
        "outputId": "3fc7f89f-8ebc-49d1-bebd-3374024f7198"
      },
      "source": [
        "# Plotting the semi factual image according to the cf found by the latent dimension loss and target class provided\n",
        "G_img= G(latent_z[40])\n",
        "G_img = G_img.to('cpu')\n",
        "npimgs = G_img[0].detach().numpy()\n",
        "#print(npimgs.shape)\n",
        "plt.imshow(npimgs[0],cmap='Greys_r')"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f370d8b16d0>"
            ]
          },
          "metadata": {},
          "execution_count": 294
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOBklEQVR4nO3df4hd9ZnH8c+TMYmYH5IoG8fUXdOgaBDWLkEWDUvW0kZFTapSG3BJ2cj0j0ZaUFjpRiouhbjYiP5hcYoh2SVrqZpoqIVmNpTVFQ2OYsfRbKMrkWacJAbBTAyYzOTZP+7JMo33fM947o9znOf9guHee5459z7czCfn3PM9537N3QVg+ptRdQMAuoOwA0EQdiAIwg4EQdiBIM7p5ouZGYf+gQ5zd2u2vKUtu5ndYGZ/NLP3zez+Vp4LQGdZ2XF2M+uRtF/StyQdlPS6pLXu/m5iHbbsQId1Yst+jaT33f0Ddz8p6VeSVrfwfAA6qJWwL5b0p0mPD2bL/oyZ9ZnZoJkNtvBaAFrU8QN07t4vqV9iNx6oUitb9hFJl0x6/LVsGYAaaiXsr0u6zMyWmNksSd+TtKs9bQFot9K78e4+bmYbJP1OUo+kLe7+Tts6A9BWpYfeSr0Yn9mBjuvISTUAvjoIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiiq1M2o5y5c+cm6xs3bsytXXnllcl1d+1Kf9X/xx9/nKxffvnlyfr69etzazNnzkyu+/DDDyfrW7ZsSdYnJiaS9WjYsgNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEMziWgMzZqT/z73vvvuS9U2bNuXWzJpO6Nk1nfz7eu2115L12267Lbd26NChdrdTG3mzuLZ0Uo2ZHZA0JmlC0ri7L2/l+QB0TjvOoPt7dz/ahucB0EF8ZgeCaDXsLmm3mb1hZn3NfsHM+sxs0MwGW3wtAC1odTd+hbuPmNlfSBows/9x95cm/4K790vqlzhAB1SppS27u49kt0ck7ZR0TTuaAtB+pcNuZnPMbN6Z+5K+LWm4XY0BaK/S4+xm9nU1tuZS4+PAf7j7zwrWYTe+iSVLliTr+/fvT9ZT4/QnTpxIrjs+Pp6sz549O1k/cOBAsn7ttdfm1vbu3Ztcd+nSpcl60TkEt956a27txRdfTK77Vdb2cXZ3/0DSX5fuCEBXMfQGBEHYgSAIOxAEYQeCIOxAEFziWgNFl7iuWrUqWT948GBubXi4tVMfenp6kvWiobsrrrgit1Y09DZ//vxk/dSpU8l6atiwm3/33ZY39MaWHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJwdHTU6Oppbu+iii5LrFl2eW7T+2NhYsj5dMc4OBEfYgSAIOxAEYQeCIOxAEIQdCIKwA0G0Y2JHBNbf35+sp8bCi87xePLJJ5P1qOPoZbFlB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEguJ4dSXfccUeyvn379mR91qxZubWtW7cm17377ruT9YmJiWQ9qtLXs5vZFjM7YmbDk5YtNLMBM3svu13QzmYBtN9UduO3SrrhrGX3S9rj7pdJ2pM9BlBjhWF395ckfXLW4tWStmX3t0la0+a+ALRZ2XPjF7n7mS8XOyRpUd4vmlmfpL6SrwOgTVq+EMbdPXXgzd37JfVLHKADqlR26O2wmfVKUnZ7pH0tAeiEsmHfJWlddn+dpBfa0w6ATikcZzezpyWtlHShpMOSfirpeUm/lvSXkj6U9F13P/sgXrPnYje+ZhYuXJisf/TRR8l6ag50SRoYGMit3Xjjjcl1GUcvJ2+cvfAzu7uvzSl9s6WOAHQVp8sCQRB2IAjCDgRB2IEgCDsQBF8lHdwTTzyRrBcNrR07dixZX7Mm/7IJhta6iy07EARhB4Ig7EAQhB0IgrADQRB2IAjCDgTBOPs0d8EFFyTrN998c7JedAl00fonTpxI1tE9bNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjG2aeBnp6e3NrQ0FBy3fPOOy9Z3717d7L+8ssvJ+uoD7bsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAE4+zTwObNm3NrF198cXLdo0ePJuu33HJLqZ5QP4VbdjPbYmZHzGx40rIHzWzEzN7Kfm7qbJsAWjWV3fitkm5osvxRd786+/lte9sC0G6FYXf3lyR90oVeAHRQKwfoNpjZULabvyDvl8ysz8wGzWywhdcC0KKyYf+FpKWSrpY0Kunneb/o7v3uvtzdl5d8LQBtUCrs7n7Y3Sfc/bSkX0q6pr1tAWi3UmE3s95JD78jaTjvdwHUQ+E4u5k9LWmlpAvN7KCkn0paaWZXS3JJByT9oIM9hnf99dcn6xs2bMitFX3v+2OPPZasnzp1KlnHV0dh2N19bZPFT3WgFwAdxOmyQBCEHQiCsANBEHYgCMIOBMElrjUwY0b6/9w777yz9PqnT59Orvv8888n61HNmTMnWb/33nuT9RUrViTrqUuL77rrruS6Rf+mediyA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQjLPXwPz585P122+/vfRzr1+/PlkfHp6+X0WwbNmy3Nrjjz+eXHflypXJetG5EUVj4ePj47m1hx56KLnuxo0bk/U8bNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjG2WvguuuuS9YXLMidXavQueee21L9888/T9aLvqo6xcyS9XPOSf95rlq1Kll/5plncmtF4+D79u1L1h955JFkfceOHcn68ePHc2utvKcpbNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjr1Jhe0xcz696L1cjixYuT9aJx9FdffTVZnzt3bm6taDz5s88+S9ZnzZqVrM+cOTNZT42lf/rpp8l1R0ZGkvXzzz8/Wb/nnntyawMDA8l1i96XOnP3pm964ZbdzC4xs9+b2btm9o6Z/ShbvtDMBszsvey2/JkfADpuKrvx45Ludfdlkv5W0g/NbJmk+yXtcffLJO3JHgOoqcKwu/uou7+Z3R+TtE/SYkmrJW3Lfm2bpDWdahJA677UufFmdqmkb0jaK2mRu49mpUOSFuWs0yepr3yLANphykfjzWyupOck/djdj02ueeMoX9ODb+7e7+7L3X15S50CaMmUwm5mM9UI+nZ3P3M5z2Ez683qvZKOdKZFAO1QuBtvjbGTpyTtc/fNk0q7JK2TtCm7faEjHU4Dr7zySrI+e/bsZL2np6f0axd95fG8efNKP/dUpIZ2iy5hffbZZ5P1nTt3JutDQ0Ol+pqupvKZ/TpJ/yDpbTN7K1v2EzVC/mszWy/pQ0nf7UyLANqhMOzu/t+S8s6M+GZ72wHQKZwuCwRB2IEgCDsQBGEHgiDsQBBc4toFY2NjyXrqEtWpSP0bnjx5MrluUb3oHICir4N+9NFHc2sPPPBAct2i3tBc6UtcAUwPhB0IgrADQRB2IAjCDgRB2IEgCDsQBOPsXVB03fZVV12VrPf29ibru3fvzq1NTEwk18X0wzg7EBxhB4Ig7EAQhB0IgrADQRB2IAjCDgTBODswzTDODgRH2IEgCDsQBGEHgiDsQBCEHQiCsANBFIbdzC4xs9+b2btm9o6Z/Shb/qCZjZjZW9nPTZ1vF0BZhSfVmFmvpF53f9PM5kl6Q9IaNeZjP+7uj0z5xTipBui4vJNqpjI/+6ik0ez+mJntk7S4ve0B6LQv9ZndzC6V9A1Je7NFG8xsyMy2mNmCnHX6zGzQzAZb6hRAS6Z8bryZzZX0X5J+5u47zGyRpKOSXNK/qLGr/48Fz8FuPNBhebvxUwq7mc2U9BtJv3P3zU3ql0r6jbsnvzmRsAOdV/pCGGtM0/mUpH2Tg54duDvjO5KGW20SQOdM5Wj8CkkvS3pb0uls8U8krZV0tRq78Qck/SA7mJd6LrbsQIe1tBvfLoQd6DyuZweCI+xAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRR+IWTbXZU0oeTHl+YLaujuvZW174keiurnb39VV6hq9ezf+HFzQbdfXllDSTUtbe69iXRW1nd6o3deCAIwg4EUXXY+yt+/ZS69lbXviR6K6srvVX6mR1A91S9ZQfQJYQdCKKSsJvZDWb2RzN738zur6KHPGZ2wMzezqahrnR+umwOvSNmNjxp2UIzGzCz97LbpnPsVdRbLabxTkwzXul7V/X0513/zG5mPZL2S/qWpIOSXpe01t3f7WojOczsgKTl7l75CRhm9neSjkv6tzNTa5nZv0r6xN03Zf9RLnD3f6pJbw/qS07j3aHe8qYZ/74qfO/aOf15GVVs2a+R9L67f+DuJyX9StLqCvqoPXd/SdInZy1eLWlbdn+bGn8sXZfTWy24+6i7v5ndH5N0ZprxSt+7RF9dUUXYF0v606THB1Wv+d5d0m4ze8PM+qpupolFk6bZOiRpUZXNNFE4jXc3nTXNeG3euzLTn7eKA3RftMLd/0bSjZJ+mO2u1pI3PoPVaez0F5KWqjEH4Kikn1fZTDbN+HOSfuzuxybXqnzvmvTVlfetirCPSLpk0uOvZctqwd1Hstsjknaq8bGjTg6fmUE3uz1ScT//z90Pu/uEu5+W9EtV+N5l04w/J2m7u+/IFlf+3jXrq1vvWxVhf13SZWa2xMxmSfqepF0V9PEFZjYnO3AiM5sj6duq31TUuySty+6vk/RChb38mbpM4503zbgqfu8qn/7c3bv+I+kmNY7I/6+kf66ih5y+vi7pD9nPO1X3JulpNXbrTqlxbGO9pAsk7ZH0nqT/lLSwRr39uxpTew+pEazeinpbocYu+pCkt7Kfm6p+7xJ9deV943RZIAgO0AFBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEP8HDDmH4vjVAisAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "4mrFWL_m39kK",
        "outputId": "210fecd2-8b5d-4e22-f07b-c2359398991c"
      },
      "source": [
        "\n",
        "\n",
        "G_img= G(z_org) #generate the img\n",
        "G_img = G_img.to('cpu')  # bring it to cpu\n",
        "npimgs = G_img[0].detach().numpy()  #plot the image\n",
        "print(npimgs.shape)\n",
        "plt.imshow(npimgs[0],cmap='Greys_r')"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3720822950>"
            ]
          },
          "metadata": {},
          "execution_count": 158
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orL7yAXZ8LYz",
        "outputId": "ff4b90ec-bdc1-4fe9-86f5-b615e888a8e4"
      },
      "source": [
        "#Using nn.losses\n",
        "#finding the journey of the digits after every 50 iterations\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "torch.manual_seed(100)\n",
        "#z_semi = torch.randn(1, 100,1,1).to(device)\n",
        "step_size = 0.1\n",
        "\n",
        "#Find the image closer to the original one but target prediction\n",
        "criterion1 = nn.MSELoss()\n",
        "nll = nn.NLLLoss()\n",
        "CE_loss = nn.CrossEntropyLoss()\n",
        "l1_loss = nn.L1Loss()\n",
        "BCE = nn.BCELoss()\n",
        "#optimizer = optim.SGD([z_semi], lr=0.01)\n",
        "\n",
        "\n",
        "#using latent dimension distance\n",
        "latent_z_journey = []\n",
        "for cnt in range(2,3,1):\n",
        "  z_semi = z_org.to(device)\n",
        "\n",
        "  overall_loss = 0\n",
        "  i=1\n",
        "  while (i<=2500):\n",
        "    z_semi.requires_grad = True\n",
        "        \n",
        "    loss1 = criterion1(z_org,z_semi) # distance using MSE\n",
        "    loss2 = CE_loss(Classifier_model_logits(G(z_semi))[1],torch.tensor([cnt]).to(device) ) # ensure the class is maintained \n",
        "    loss3 = BCE(D(G(z_semi)), torch.tensor([1.0]).to(device))\n",
        "\n",
        "       \n",
        "    #loss =  loss1 + loss2  # without PR\n",
        "    loss = loss1 + loss2 + 0.01*loss3 #with PR\n",
        "    \n",
        "    z_semi.grad = None\n",
        "    loss.backward(retain_graph=True)  \n",
        "    #optimizer.step()  \n",
        "    z_semi.requires_grad = False\n",
        "    z_semi = z_semi - z_semi.grad * step_size\n",
        "    i = i+1\n",
        "    overall_loss= overall_loss + loss \n",
        "\n",
        "    if (i%50==0):\n",
        "           \n",
        "      avg_loss = overall_loss/50.0\n",
        "      print(\"avg_loss \" + \"step \" + \" \" +str(i) + str (avg_loss))\n",
        "     \n",
        "      overall_loss = 0 \n",
        "      latent_z_journey.append(z_semi)\n",
        "  \n",
        "  "
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.4459e-13, 4.2414e-08, 8.0479e-09, 9.9997e-01, 5.9251e-14, 4.1177e-09,\n",
              "         2.8320e-14, 2.8318e-05, 1.5183e-10, 5.2207e-08]], device='cuda:0',\n",
              "       grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMhCvRGtXjyl",
        "outputId": "346148b5-d0a8-4f77-900b-9737be5eb832"
      },
      "source": [
        "# Plotting the counterfactual image iteration wise \n",
        "G_img= G(latent_z_journey[40])\n",
        "G_img = G_img.to('cpu')\n",
        "npimgs = G_img[0].detach().numpy()\n",
        "#print(npimgs.shape)\n",
        "plt.imshow(npimgs[0],cmap='Greys_r')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.7616e-03, 3.0601e-05, 9.9420e-01, 2.9991e-03, 2.4383e-08, 2.4623e-07,\n",
              "         4.0001e-06, 5.8101e-06, 7.3204e-08, 2.2983e-07]], device='cuda:0',\n",
              "       grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFzrer3duXem"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut077CP0nLRD"
      },
      "source": [
        "## Semifactual calculation using standard losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J7G5KMBnQhN"
      },
      "source": [
        "#Using nn.losses\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "torch.manual_seed(100)\n",
        "#z_semi = torch.randn(1, 100,1,1).to(device)\n",
        "step_size = 0.1\n",
        "\n",
        "#Find the image closer to the original one but target prediction\n",
        "criterion1 = nn.MSELoss()\n",
        "nll = nn.NLLLoss()\n",
        "CE_loss = nn.CrossEntropyLoss()\n",
        "l1_loss = nn.L1Loss()\n",
        "BCE = nn.BCELoss()\n",
        "#optimizer = optim.SGD([z_semi], lr=0.01)\n",
        "\n",
        "\n",
        "#using latent dimension distance\n",
        "latent_z = []\n",
        "for cnt in range(2,3,1):\n",
        "  z_semi = z_org.to(device)\n",
        "  arg_max = 0.01\n",
        "  overall_loss = 0\n",
        "  i=1\n",
        "  \n",
        "  while (torch.topk(Classifier_model_logits(G(z_semi))[0][0],2).indices[0] ==0 and torch.topk(Classifier_model_logits(G(z_semi))[0][0],2).indices[1] ==2  ):\n",
        "    z_semi.requires_grad = True\n",
        "        \n",
        "    loss1 = criterion1(z_org,z_semi) # distance using MSE\n",
        "    loss2 = CE_loss(Classifier_model_logits(G(z_semi))[1],torch.tensor([cnt]).to(device) ) # ensure the class is maintained \n",
        "    loss3 = BCE(D(G(z_semi)), torch.tensor([1.0]).to(device))\n",
        "    arg_max = torch.argmax(Classifier_model_logits(G(z_semi))[0][0])\n",
        "    print(arg_max)\n",
        "       \n",
        "    #loss =  loss1 + loss2  # without PR\n",
        "    loss = loss1 + loss2 + 0.01*loss3 #with PR\n",
        "    \n",
        "    z_semi.grad = None\n",
        "    loss.backward(retain_graph=True)  \n",
        "    #optimizer.step()  \n",
        "    z_semi.requires_grad = False\n",
        "    z_semi = z_semi - z_semi.grad * step_size\n",
        "    i = i+1\n",
        "    print(i)\n",
        "    overall_loss= overall_loss + loss \n",
        "\n",
        "    if (i%500==0):\n",
        "           \n",
        "      avg_loss = overall_loss/500.0\n",
        "      print(\"avg_loss \" + \"step \" + \" \" +str(i) + str (avg_loss))\n",
        "     \n",
        "      overall_loss = 0 \n",
        "  latent_z.append(z_semi)\n",
        "  \n",
        "  "
      ],
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gK6rN61oFxC",
        "outputId": "a3a9e137-14b2-4079-851f-5b15a3959a37"
      },
      "source": [
        "torch.abs(Classifier_model_logits(G(z_semi))[0][0][0] -Classifier_model_logits(G(z_semi))[0][0][2])"
      ],
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1284, device='cuda:0', grad_fn=<AbsBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 325
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8PCJp_8qZBN",
        "outputId": "1ae473e4-21d8-44f6-d375-4dc01d93bdf2"
      },
      "source": [
        "Classifier_model_logits(G(z_semi))[0][0]\n"
      ],
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4.3783e-08, 1.6882e-01, 8.3117e-01, 2.4964e-08, 1.1351e-08, 3.9926e-10,\n",
              "        6.2857e-07, 1.2927e-07, 7.4876e-08, 5.9644e-12], device='cuda:0',\n",
              "       grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 340
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xr43rP_q5yn",
        "outputId": "b3229f12-9ad6-4630-9640-cdc3b7709e53"
      },
      "source": [
        "torch.topk(Classifier_model_logits(G(z_semi))[0][0],2).indices"
      ],
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.topk(values=tensor([0.9983, 0.0016], device='cuda:0', grad_fn=<TopkBackward>), indices=tensor([0, 6], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "5pP-Uhk4oNU2",
        "outputId": "f88977ba-694e-442d-ca85-f38dc43d97b7"
      },
      "source": [
        "\n",
        "\n",
        "G_img= G(z_semi) #generate the img\n",
        "G_img = G_img.to('cpu')  # bring it to cpu\n",
        "npimgs = G_img[0].detach().numpy()  #plot the image\n",
        "print(npimgs.shape)\n",
        "plt.imshow(npimgs[0],cmap='Greys_r')"
      ],
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f370d66e250>"
            ]
          },
          "metadata": {},
          "execution_count": 336
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOl0lEQVR4nO3db4xVdX7H8c+XATLKnwRqnBChupJJDNHIEvwTOzFbN25cHoj7ZAPGinaT2QcY19jEmu0DjE0TU902jZJN2K5ZaNDNJmCZbEwXi0QtCRsHQgGHtlLkj4Q/oUicjSIC3z64h82A9/zOcM+591zm+34lk7lzv3PO+eYOH86553fP+Zm7C8DEN6nuBgB0BmEHgiDsQBCEHQiCsANBTO7kxsys1Kn/3t7e3NrZs2fLrBqYMNzdmj1fKuxm9pCkf5LUI+mf3f2lMusrcuutt+bWRkZG2rlp4JrX8mG8mfVIWi3p+5IWSFpuZguqagxAtcq8Z79b0n53P+Du5yT9WtLSatoCULUyYb9J0pExP3+aPXcZMxs0s2EzGy6xLQAltf0EnbuvkbRGKn+CDkDryuzZj0qaN+bnudlzALpQmbB/KKnfzL5lZlMlLZM0VE1bAKrW8mG8u583s6ck/U6NobfX3f2jyjpr4rPPPsut9fT0JJe9cOFC1e0A15RS79nd/W1Jb1fUC4A24uOyQBCEHQiCsANBEHYgCMIOBEHYgSA6ej37vHnz9Nxzz+XW77vvvuTyM2fOzK098cQTyWW3bduWrAMTHXt2IAjCDgRB2IEgCDsQBGEHgiDsQBAdHXqTpIsXL+bWzp07l1x2eDj/zlanT59uuScgAvbsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxCEuXdukpZJkyZ5atrlr7/+Orl8aow+VUN9zpw5k1ubMWNGctlnn302WX/ttdeS9ai3D8+bspk9OxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4E0fFx9smT8y+hLxpnx7Vn+/btubV77rknuezhw4eT9YGBgWT9yJEjyfpElTfOXurmFWZ2UNKopAuSzrv74jLrA9A+Vdyp5s/d/VQF6wHQRrxnB4IoG3aXtNnMdpjZYLNfMLNBMxs2s+FOnh8AcLmyh/ED7n7UzG6U9I6Z/Ze7vz/2F9x9jaQ1UuMEXcntAWhRqT27ux/Nvp+U9Jaku6toCkD1Wg67mU0zsxmXHkv6nqS9VTUGoFplDuP7JL1lZpfW84a7/1tqAXdnLH2CmTp1arLe39/f8rr7+vqS9SeffDJZf/HFF1ve9kTUctjd/YCkOyvsBUAbMfQGBEHYgSAIOxAEYQeCIOxAEB2fshkTy/Tp05P1ottFp+zfvz9Zf/XVV1ted0Ts2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZUUp2iXOunp6e3FrRbcqKLoceHR1N1nE59uxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EATj7Chl3bp1yfqkSfn7k6Jx9JdffjlZP3/+fLKOy7FnB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgrOia4ko3Zta5jaES06ZNS9ZPnTqVrPf29ubWRkZGksveeWd6kmDG2Ztz96Y3GSjcs5vZ62Z20sz2jnlutpm9Y2YfZ99nVdksgOqN5zD+V5IeuuK55yVtcfd+SVuynwF0scKwu/v7kk5f8fRSSWuzx2slPVJxXwAq1upn4/vc/Vj2+LikvrxfNLNBSYMtbgdARUpfCOPunjrx5u5rJK2ROEEH1KnVobcTZjZHkrLvJ6trCUA7tBr2IUkrsscrJG2qph0A7VI4zm5mb0r6jqQbJJ2QtErSv0r6jaQ/lXRI0g/d/cqTeM3WxWF8l0ldby5JO3fuTNaLxsJT16z39/cnlz106FCyjubyxtkL37O7+/Kc0ndLdQSgo/i4LBAEYQeCIOxAEIQdCIKwA0FwK+ng7r333mT9jjvuKLX+oaGh3Nrhw4dLrRtXhz07EARhB4Ig7EAQhB0IgrADQRB2IAjCDgTBOPsEZ9b0asc/euyxx5L1oktgi27nvHXr1txaJ29jDvbsQBiEHQiCsANBEHYgCMIOBEHYgSAIOxAE4+wT3HXXXZes33XXXaXWf+DAgWR99erVpdaP6rBnB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgGGef4B5//PFkfdGiRaXW/8UXX5RaHp1TuGc3s9fN7KSZ7R3z3AtmdtTMdmVfS9rbJoCyxnMY/ytJDzV5/h/dfWH29Xa1bQGoWmHY3f19Sac70AuANipzgu4pM9udHebPyvslMxs0s2EzGy6xLQAltRr2n0uaL2mhpGOSfpb3i+6+xt0Xu/viFrcFoAIthd3dT7j7BXe/KOkXku6uti0AVWsp7GY2Z8yPP5C0N+93AXQHK7p3t5m9Kek7km6QdELSquznhZJc0kFJP3b3Y4UbM+NG4W2wcOHC3Nq2bduSy15//fWltr1gwYJkfd++faXWj6vn7k0nCyj8UI27L2/y9C9LdwSgo/i4LBAEYQeCIOxAEIQdCIKwA0Fwies1oGja5C1btuTWim4lffHixWR9cHAwWb9Wh9aKprJu93TSDzzwQG5t+/btyWVbvayYPTsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBME4excoGke///77k/UZM2bk1orGi6dOnZqsX7hwIVlvp8mT0/88d+3alazPnz8/t7Zjx47ksg8++GCy/uWXXybrRX/TFStW5NbWrVuXXPb222/PrY2Ojub3lFwrgAmDsANBEHYgCMIOBEHYgSAIOxAEYQeCYJy9A4rGXIvGdNevX5+sT5kyJbdWNB5c9rrthx9+OFnfvXt3bu22225LLjs0NJSsF43Df/LJJ7m1jRs3Jpf96quvkvUiRfcJSL1un3/+eXLZ1LXw7777bm6NPTsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBME4ewds2LAhWV+yZEmyfu7cuWQ9dc355s2bk8vOnDkzWV+9enWyvmzZsmQ9dX/2onu3F41V79mzJ1kfGBjIraWu++6EWbNmdXybhXt2M5tnZlvNbMTMPjKzn2TPzzazd8zs4+x757sHMG7jOYw/L+mv3H2BpHslrTSzBZKel7TF3fslbcl+BtClCsPu7sfcfWf2eFTSPkk3SVoqaW32a2slPdKuJgGUd1Xv2c3sFknflvR7SX3ufiwrHZfUl7PMoKT0hGEA2m7cZ+PNbLqkDZKecffLPqnvjaspml5R4e5r3H2xuy8u1SmAUsYVdjObokbQ17v7pcuFTpjZnKw+R9LJ9rQIoApWdImjNcZH1ko67e7PjHn+ZUn/5+4vmdnzkma7+3OpdfX29vrcuXNz66tWrUr2cubMmdza008/nVy2TufPn0/We3p62rbtspewFg2Pldl+0W2qP/jgg2T90UcfTdaPHz+erE9U7t70jzae9+x/JukvJO0xs0s36v6ppJck/cbMfiTpkKQfVtEogPYoDLu7/4ekvP/ev1ttOwDahY/LAkEQdiAIwg4EQdiBIAg7EEThOHuVFi1a5O+9915uffr06cnlU+Oyqdsp1+3gwYPJ+s0339y2bZf9+xZdZjo8PJysr1y5Mre2f//+5LJFt3M+e/Zsst7NUp9fKPs3yxtnZ88OBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0F0dJzdzDw1fXHRePSNN96YW+vt7W21rdoVjbNv2rQpWZ8/f35u7ZVXXkku+8YbbyTrRWPhnfz3g/FhnB0IjrADQRB2IAjCDgRB2IEgCDsQBGEHguj4OHvHNgYExTg7EBxhB4Ig7EAQhB0IgrADQRB2IAjCDgRRGHYzm2dmW81sxMw+MrOfZM+/YGZHzWxX9rWk/e0CaFXhh2rMbI6kOe6+08xmSNoh6RE15mP/g7un745w+br4UA3QZnkfqhnP/OzHJB3LHo+a2T5JN1XbHoB2u6r37GZ2i6RvS/p99tRTZrbbzF43s1k5ywya2bCZpecJAtBW4/5svJlNl/SepL9z941m1ifplCSX9LdqHOr/ZcE6OIwH2izvMH5cYTezKZJ+K+l37v4PTeq3SPqtu99esB7CDrRZyxfCWGO6yV9K2jc26NmJu0t+IGlv2SYBtM94zsYPSPpA0h5Jl+bv/amk5ZIWqnEYf1DSj7OTeal1sWcH2qzUYXxVCDvQflzPDgRH2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCKLwhpMVOyXp0Jifb8ie60bd2lu39iXRW6uq7O3mvEJHr2f/xsbNht19cW0NJHRrb93al0RvrepUbxzGA0EQdiCIusO+pubtp3Rrb93al0RvrepIb7W+ZwfQOXXv2QF0CGEHgqgl7Gb2kJn9t5ntN7Pn6+ghj5kdNLM92TTUtc5Pl82hd9LM9o55braZvWNmH2ffm86xV1NvXTGNd2Ka8Vpfu7qnP+/4e3Yz65H0P5IelPSppA8lLXf3kY42ksPMDkpa7O61fwDDzO6X9AdJ6y5NrWVmfy/ptLu/lP1HOcvd/7pLentBVzmNd5t6y5tm/AnV+NpVOf15K+rYs98tab+7H3D3c5J+LWlpDX10PXd/X9LpK55eKmlt9nitGv9YOi6nt67g7sfcfWf2eFTSpWnGa33tEn11RB1hv0nSkTE/f6rumu/dJW02sx1mNlh3M030jZlm67ikvjqbaaJwGu9OumKa8a557VqZ/rwsTtB904C7L5L0fUkrs8PVruSN92DdNHb6c0nz1ZgD8Jikn9XZTDbN+AZJz7j752Nrdb52TfrqyOtWR9iPSpo35ue52XNdwd2PZt9PSnpLjbcd3eTEpRl0s+8na+7nj9z9hLtfcPeLkn6hGl+7bJrxDZLWu/vG7OnaX7tmfXXqdasj7B9K6jezb5nZVEnLJA3V0Mc3mNm07MSJzGyapO+p+6aiHpK0Inu8QtKmGnu5TLdM4503zbhqfu1qn/7c3Tv+JWmJGmfk/1fS39TRQ05ft0r6z+zro7p7k/SmGod1X6txbuNHkv5E0hZJH0v6d0mzu6i3f1Fjau/dagRrTk29DahxiL5b0q7sa0ndr12ir468bnxcFgiCE3RAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EMT/A42IssxYBUXuAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBJ0rDBro3dI",
        "outputId": "227dc469-402e-4049-b83d-62619b9fae5c"
      },
      "source": [
        "Classifier_model_logits(G(z_semi))[0]"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9.0800e-12, 5.5329e-08, 1.4080e-07, 2.9251e-06, 2.1534e-12, 1.7786e-12,\n",
              "         1.8610e-13, 1.0000e+00, 9.9023e-12, 1.9158e-08]], device='cuda:0',\n",
              "       grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAb98l1Qo311",
        "outputId": "8156c876-67c4-4961-d55a-374c50cef38d"
      },
      "source": [
        "Classifier_model_logits(G(z_semi))[0][0][2]"
      ],
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1284, device='cuda:0', grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 327
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgJQosUvo7Ns"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}